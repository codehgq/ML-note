{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 k 近邻算法改进网站的配对效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入矩阵运算模块\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**文件到矩阵转换（准备数据）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集文件datingTestSet2.txt保存在当前目录下，也即是把txt拷贝到本地的用户文件夹下（我的）\n",
    "输入：文件  输出：数据集的特征矩阵returnMat和标签向量classLabelVector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2matrix(filename):\n",
    "    love_dictionary = {'largeDoses':3, 'smallDoses':2, 'didntLike':1}    # 三个类别\n",
    "    fr = open(filename)    # 打开文件\n",
    "    arrayOLines = fr.readlines()    # 逐行打开\n",
    "    numberOfLines = len(arrayOLines)            #得到文件的行数\n",
    "    returnMat = np.zeros((numberOfLines, 3))        #初始化特征矩阵\n",
    "    classLabelVector = []                       #初始化输出标签向量\n",
    "    index = 0\n",
    "    for line in arrayOLines:#循环处理文件中的每行数据\n",
    "        line = line.strip()    # 删去字符串首部尾部空字符\n",
    "        listFromLine = line.split('\\t')    # 按'\\t'对字符串进行分割，得到列表\n",
    "        returnMat[index, :] = listFromLine[0:3]    # listFromLine的0,1,2元素是特征，赋值给returnMat的当前行\n",
    "        if(listFromLine[-1].isdigit()):    # 如果listFromLine最后一个元素是数字\n",
    "            classLabelVector.append(int(listFromLine[-1]))    # append 的作用是在列表的末尾添加元素，直接赋值给classLabelVector\n",
    "        else:    # 如果listFromLine最后一个元素不是数字，而是字符串\n",
    "            classLabelVector.append(love_dictionary.get(listFromLine[-1]))    # 根据字典love_dictionary转化为数字\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector    # 返回的类别标签classLabelVector是1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据归一化**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：数据矩阵 输出：归一化的数据矩阵normDataSet 范围 ranges 有3列 最小值minVals 3列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoNorm(dataSet):\n",
    "    minVals = dataSet.min(0)#从列中选择最小值\n",
    "    maxVals = dataSet.max(0)#从列中选择最大值\n",
    "    ranges = maxVals - minVals\n",
    "    normDataSet = np.zeros(np.shape(dataSet))#shape返回矩阵中维度 此句相当于创建一个同等规模的0矩阵\n",
    "    m = dataSet.shape[0]#取矩阵的行数\n",
    "    normDataSet = dataSet - np.tile(minVals, (m, 1))#函数title用于扩充minVals成m行1列\n",
    "    normDataSet = normDataSet/np.tile(ranges, (m, 1))   # normDataSet值被限定在[0,1]之间\n",
    "    return normDataSet, ranges, minVals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN分类器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：测试集inX，训练集dataSet，训练样本标签lebels，取的最近邻个数k 输出：返回K近邻中所属类别最多的一类\n",
    "参考：https://www.cnblogs.com/vrfighters/articles/4715527.html 写的不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify0(inX, dataSet, labels, k):\n",
    "    dataSetSize = dataSet.shape[0]#得到行数\n",
    "    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet#title 相当于将inX扩充为dataSeetSize行目的是为了和后面的训练集求距离\n",
    "    sqDiffMat = diffMat**2\n",
    "    sqDistances = sqDiffMat.sum(axis=1)#求和axis=1表示对所在行的全部列求和\n",
    "    distances = sqDistances**0.5\n",
    "    sortedDistIndicies = distances.argsort()#从小到大排序并找到索引值可参考：https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html和https://www.cnblogs.com/yyxf1413/p/6253995.html\n",
    "    classCount = {}#创建字典，用于存储各标签出现的次数\n",
    "    for i in range(k):#从上述的k个排序好的点，统计类别次数\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]#解释 距离最小的数据样本的标签参考\n",
    "                                                   #：https://blog.csdn.net/zengxyuyu/article/details/54382182\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1#获取键值voteIlabel对应的值（次数），若不存在则为0\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)#将字典分解为元组列表，并按照第二个元素（次数）排序 true 为降序排列 默认升序 \n",
    "    #参考：http://www.runoob.com/python/python-func-sorted.html\n",
    "    return sortedClassCount[0][0]#得到k近邻中所属类别最多的类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试算法（完整程序需要调用前面的子函数）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "输入：样本，输出：分类结果和实际类别 ，错误率，错误个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datingClassTest():\n",
    "    hoRatio = 0.10      #整个数据集的10%用来测试\n",
    "    datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')       #导入数据集\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)    # 所有特征归一化\n",
    "    m = normMat.shape[0]    # 样本个数（行）\n",
    "    numTestVecs = int(m*hoRatio)    # 测试样本个数\n",
    "    errorCount = 0.0\n",
    "    #对测试数据遍历\n",
    "    for i in range(numTestVecs):\n",
    "        #对每一条数据进行分类\n",
    "        classifierResult = classify0(normMat[i, :], normMat[numTestVecs:m, :], datingLabels[numTestVecs:m], 3)\n",
    "       #输出分类结果和实际的类别\n",
    "        print(\"the classifier came back with: %d, the real answer is: %d\" % (classifierResult, datingLabels[i]))\n",
    "      #如果分类结果和实际不符\n",
    "    if (classifierResult != datingLabels[i]): errorCount += 1.0\n",
    "    print(\"the total error rate is: %f\" % (errorCount / float(numTestVecs)))    # 打印错误率\n",
    "    print(errorCount)    # 打印错误个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 1\n",
      "the total error rate is: 0.050000\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "datingClassTest() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用算法（构建完整可用系统）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依据用户输入3个参数，输出：判断结果类别\n",
    "详细注释;参考：https://blog.csdn.net/quincuntial/article/details/50471423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPerson():\n",
    "    resultList = ['not at all', 'in small doses', 'in large doses']#定义分类结果类别\n",
    "   #读取输入的数据  percentTats  ffMiles  iceCream\n",
    "    percentTats = float(input(\\\n",
    "                                  \"percentage of time spent playing video games?\"))\n",
    "    ffMiles = float(input(\"frequent flier miles earned per year?\"))\n",
    "    iceCream = float(input(\"liters of ice cream consumed per year?\"))\n",
    "    #从文件datingTestSet2.txt中读取已有数据\n",
    "    datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)#归一化\n",
    "    #将单个数据定义为一条数据\n",
    "    inArr = np.array([ffMiles, percentTats, iceCream, ])\n",
    "    #对输入数据分类\n",
    "    classifierResult = classify0((inArr - \\\n",
    "                                  minVals)/ranges, normMat, datingLabels, 3)\n",
    "    #输出预测的分类结果\n",
    "    print(\"You will probably like this person: %s\" % resultList[classifierResult - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of time spent playing video games?100\n",
      "frequent flier miles earned per year?200\n",
      "liters of ice cream consumed per year?300\n",
      "You will probably like this person: in large doses\n"
     ]
    }
   ],
   "source": [
    "classifyPerson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
